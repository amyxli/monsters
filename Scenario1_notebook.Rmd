---
title: 'Scenario 1: Using fitted model from published data '
output:
  html_document:
    df_print: paged
  pdf_document: default
---
Kumle, L., Vo, M. L-H., & Draschkow, D.

latest update: August 2019

***
***
Sufficient power and precision in confirmatory analyses are important for the reliability, replicability, and interpretation of empirical findings. Calculating power, however, is not necessarily a trivial task and in certain cases this might pose a feasibility barrier to scientists. One of these cases is power analysis for liner mixed-effect models (LMMs). LMMs are a powerful tool for modelling fixed and random effects simultaneously, but do not offer a feasible analytic solution to estimate the probability that a test correctly rejects the null hypothesis.

A flexible and more intuitive alternative approach are simulation-based power analyses which can use a linear-mixed model fitted with *lme4* (Bates, Maechler, Bolker & Walker, 2015) to inform the parameters of the simulation. For more details on the theoretical background see Kumle, Vo & Draschkow (in preparation).

In this notebook we outline a scenario in which published studies and data are available and used as a starting point. First, we will demonstrate how to estimate power for single effects using the SIMR package (Green & Macleod, 2016). Next, we will utilise [*mixedpower*](https://github.com/DejanDraschkow/mixedpower) (Kumle, Vo & Draschkow, 2018) to simulate power for all specified effects  simultaneously.

***
***

###**Import Data**

&nbsp;

Data used for this tutorial originates from Yan, Zhou, Shu, Yusupu, Miao, Kruegel & Kliegl (2014). All analyses and data were obtained from [http://read.psych.uni-potsdam.de](http://read.psych.uni-potsdam.de/index.php?option=com_content&view=article&id=132:yan-et-al-2014-cognition-eye-movements-guided-by-morphological-structure-evidence-from-the-uighur-language&catid=12:publications&Itemid=11) where the authors made them available.

In their eye-tracking experiment, Yan et al. (2014) examined the influence of word length, launch site, morphological complexity and word frequency on first landing positions (FLP) during reading. The data contains 48 subjects, each of whom read 120 sentences.

We will use this data set to run a power analysis for a planned study investigating and confirming the influence of different parameters on first landing positions while reading.

To focus on the actual power analysis procedure we already preprocessed the data set according to the author's analysis which can be downloaded [here](https://www.dropbox.com/s/ply8xkg123d4ee0/Yan_et_al.RData?dl=0).  

```{r}
# get data
load("Yan_et_al.RData") # data set is called "YanData"
```

Informing the parameters of the simulation is a critical step and this tutorial is aimed at GLMMs/LMMs fitted with lme4 a power analysis in this context starts with such a model. 


In this tutorial, we will use a simplified version of the final model provided by Yan et al. (2014). 
The full analysis and data can be found at [http://read.psych.uni-potsdam.de](http://read.psych.uni-potsdam.de/index.php?option=com_content&view=article&id=132:yan-et-al-2014-cognition-eye-movements-guided-by-morphological-structure-evidence-from-the-uighur-language&catid=12:publications&Itemid=11).

Let's have a look at our model: 

```{r}
library(lme4)
# simplified LMM to simulate power for
FLPmodel <- lmer(flp ~ wl.c * ls.c * sn.c + (1|nsub) + (1|nsen),
                 data=data)

summary(FLPmodel, corr = F)
```

 Variable descriptions: 
 
     wl.c: centered word length
     ls.c: centered launch site
     sn.c: centered number of suffixes
     nsub: subject ID variable
     nsen: sentence variable (stimulus)
     wid: variable coding the individual words
     
As we can see, FLPmodel looks at the effects of word length, launch site and number of suffixes (morphological complexity) on the first landing position while reading as well as at their interactions. As random factors we specified between-subject and between-item variance. 

***
***

###**Power Analysis with SIMR**  

&nbsp;

First, we will simulate power for one specific effect in the FLPmodel using SIMR (Green & Macleod, 2016). For an extensive tutorial on the different functions and options included in SIMR see [Green & Macleod (2016)](https://doi.org/10.1111/2041-210X.12504).

Let's assume our effect of interest for a follow-up study is *morphological complexity* (i.e. number of suffixes). To justify and decide on a sample size for this study, we decide to run a power analysis based completely on the published data and fitted model.

To do so, we first need to install and load the SIMR package (Green & Macleod, 2016). Note that SIMR only needs to be installed once and loading the package is sufficient once it is installed.

```{r eval=FALSE, message=FALSE, warning=FALSE}
## install SIMR
install.packages("simr")
```

```{r message=FALSE, warning=FALSE}
# load SIMR
library(simr)
```
&nbsp;
&nbsp;

#### Running the power analysis

SIMR offers two easy-to-use functions which can be used to simulate and examine power in a mixed model. As we are interested in confirming the effect size of morphological complexity (= -0.078595), we will not modify this effect size and the model.

In a first step, we will simulate power for exactly the number of subjects and the specified effect size in our FLPmodel. For this, we can use the powerSim()-function. Explore ?powerSim for a treatment of all possible argument specification.

**Note**: SIMR can simulate power for only one effect at a time and as a default runs the simulation for the first effect specified in the model. It therefor is important to specify morphological complexity (i.e. "sn.c"") as the effect of interest.

```{r include=FALSE}
# load output in the background
load("~/Dropbox/Power/notebooks/simr_power_scenario1_snc.Rdata")
```

```{r eval= F, warning=FALSE}
# run power analysis
power <- powerSim(fit = FLPmodel, test = fixed("sn.c"))
```

```{r eval = F}
# let's have a look at the results
print(power)

# --> output will be included soon!
```

The output tells us that power for the effect size of world length is 94 %. Remember that the FLPmodel was fitted with data from 48 participants. The power value we get from this analysis gives us a first impression of the power linked to our effect of interest but does not really help us to choose a sample size for our future study. For this, running a simulation based on different sample sizes would be much more informative.

To do exactly this, SIMR offers the powerCurve() - function to explore the relationship of sample size and power. Let's run such an analysis on our effect of interest in order to investigate the *sample size x power* relationship. 

Although, before we can hand over the FLPmodel to powerCurve() we need to "extend" it to the largest sample size we are interested in. The SIMR function 'extend()' duplicates data used to fit the model to simulate more participants. For this to work we need to provide the function with the variable containing the subject ID and the largest sample size we are interested in. As morphological complexity ("sn.c") already had a power of 94% with 48 subjects, we decide that the largest sample size we are interested in is 60.

```{r eval = F}
# extend FLPmodel to use powerCurver()
FLPmodel_extended <- extend(FLPmodel, along="nsub", n = 60)

```

To now run a power analysis over multiple sample sizes, we simply need to hand over our extended model and specify the different sample sizes we are interested in ("breaks"). moreover, we need to tell SIMR which variable it should use to subset the extended model to the different sample sizes ("along").

```{r include=FALSE}
# let's have a look!
load("~/Dropbox/Power/notebooks/simr_powerC_scenario1_snc.Rdata")
```

```{r eval = F}
# run power analysis
powerC <- powerCurve(fit = FLPmodel_extended, test = fixed("sn.c"), along = "nsub",
                      breaks = c(30, 40, 60, 70))
```

```{r}
# let's have a look at the results
print(powerC)
```
As can be expected, power is lower for smaller sample sizes. To use this output to decide on a sample size for our future study, we first need to agree on a goal power.  A well-known threshold value for the probability of finding an effect in cognitive neuroscience and psychology is 80% and represents a compromise between the need for adequate power and the effort/cost needed to further increase power (Brysbaert & Stevens, 2018). Using this threshold, we would aim to test a sample size greater than 40.

***
***
In conclusion, using SIMR can be especially useful for scenarios in which there is a single effect of interest. However, there are cases when more than one effect from a model are of interest. Running a separate power analysis for each effect can be very time consuming (note the runtime of over 60 hours to simulate power for one effect and different sample sizes above) and it would be more convenient to just simulate power for all effects at once.

Another tool for simulation-based power analysis is [*mixedpower*](https://github.com/DejanDraschkow/mixedpower) (Kumle, Vo & Draschkow, 2018) which allows to simulate power for all effects in a model. 

In the following section, we will conduct a power analysis with mixedpower.


***
***

###**Power Analysis with mixedpower**

&nbsp;

Similar to SIMR, a power analysis in mixedpower starts with a fitted model and for that we again will work with our FLPmodel.
Before we can start mixedpower needs to be installed. The package is hosted on [GitHub](https://github.com/DejanDraschkow/mixedpower) and the devtools package is required to install it.

```{r eval = F}
# install mixedpower package
if (!require("devtools")) {
    install.packages("devtools", dependencies = TRUE)}
devtools::install_github("DejanDraschkow/mixedpower")

```

&nbsp;

#### **A function for calculating power**

Once the library is loaded we can use the mixedpower() function to perform the power analysis.
```{r eval=FALSE, message=FALSE, warning=FALSE}
library(mixedpower)

#core function to perform power analysis
mixedpower(model_emp, data_emp, subvar, fixed_effects,
           sample_sizes, n_sim, critical_value, confidence_level,
           databased = T, safeguard = T, rnorm = F)

```

A general introduction to mixedpower can be found [here](https://lkumle.github.io/power_notebooks/mixedpower_introduction.html). In the following section, we will specify all relevant parameters without going into detail of the inner working of mixedpower. To gain a better understanding on why each parameter is needed we recommend reading the general introduction first.

&nbsp;

#### **Empirical data and model**

Above, we already loaded our data and specified a final model we want to work with. We can use our fitted model (model_emp = FLPmodel) and our data frame as the data set (data_emp = YanData).

The function requires further specifics about the data at hand including the name of the column containing the subject identifier (subvar) and the names of the fixed effects specified in the model (fixed_effects).

```{r eval = F}
# specfiy necessary information about data set
model_emp <- FLPmodel
data_emp <- YanData
subvar <- "nsub"
fixed_effects <- c("wl.c","ls.c", "sn.c")
```

&nbsp;

#### **Simulation of multiple data sets**

As noted before, power in a simulation-based approach is computed as the proportion of significant simulations to all simulations. Thus, we need to define the number of simulations we want to run. We suggest running at least 1000 simulations (n_sim = 1000) but fewer runs can be used to check if the analysis is running smoothly.

Similar to the powerCurve() function in SIMR, mixedpower allows to simulate power over a range of sample sizes. For that, we need to specify the sample sizes we want to simulate power for. Using the original sample size of the study on hand as an anchor, we will indicate a range of plausible sample sizes (sample_sizes = c(20, 30, 40, 48, 60)) and n_sim simulations will be conducted for each sample size. 

```{r}
# simulation parameters
n_sim <- 1000
sample_sizes <- c(20, 30, 40, 48, 60)
```

&nbsp;

#### **Test of statistical significance**

Deciding if an effect exceeds a significance threshold is a critical aspect of every simulation-based power analysis and heavily influences its outcome. In general, rising this threshold will lead to lower estimated power as it becomes harder to reach it and vice versa.  Mixedpower relies on lme4, which does not provide p-values. Even though there are methods available to compute p-values in mixed models, they are affiliated with ambiguity because degrees of freedom are hard to determine. Mixedpower therefore works with the available t values for linear mixed models or z values for generalised linear mixed models. Concluding, we need to set a critical_value in form of a t or z  values depending on the model on hand and all coefficients exceeding this value would be counted as significant. In the present example, we decided to set critical_value = 2.

```{r}
# set critical_value
critical_value <- 2
```


&nbsp;

#### **Protection against bias in data**

The accuracy of a simulation-based calculation of power and its interpretability is dependent on how well the model is capturing the data (Thomas & Juanes, 1996) and on how well the data is capturing the underlying effect of interest. Especially data consisting of only few observations or participants, (e.g. from pilot or exploratory studies) carry the risk of uncertainty in respect to effects in the data.

Mixedpower adapted the safeguard option introduced by Perugini et al. (2014). For more background information see the main tutorial or the [general introduction](https://lkumle.github.io/power_notebooks/mixedpower_introduction.html) to mixedpower.
As safeguard power computes a confidence interval around the beta coefficients, we need to specify the width of this confidence interval. In the present example, we will set it to 0.68 representing the width of one standard deviation.  
```{r}
# set width of confidence interval
confidence_level <- 0.68
```

&nbsp;

#### **Power simulation**

Now we are all set to run the power simulation for the data at hand. For this, we will use the function mixedpower() which handles and combines simulations for all specified sample sizes and provides us with a power estimate derived from the actual effect sizes of the data (databased), as well as the conservative estimate of safeguard power (safeguard). The relevant parameters specified in the steps above will be used.
**Note**: 'rnorm' is an experimental option for a more conservative simulation that is not discussed in this tutorial. It therefor is set to FALSE to exclude it from the simulation. 


```{r eval=FALSE, message=FALSE, warning=FALSE}
power_output <- mixedpower(model_emp, data_emp, subvar, fixed_effects,
                           sample_sizes, n_sim, critical_value, confidence_level,
                           databased = T, safeguard = T)
```

&nbsp;

####**Interpreting and visualizing the power analysis **

The output provided by mixedpower()  contains power values for every effect and all specified sample sizes. The power values are provided both from the original effect sizes (databased) or the corrected conservative estimates (safeguard).

```{r include=FALSE}
# load output!! >> include this <<
load("~/Dropbox/Power/notebooks/mixedpower_scenario1.Rdata")
```

```{r}
power_output
```
What do we see here?

power_output contains power values for every effect and  interactions for all sample sizes we specified. Additionally, power_output includes the mode (databased and safeguard) which specifies if a correcting of the effect size was applied. Plotting our results can give us a better impression so let's use the mixedpower function multiplotPower() to do so: 


```{r eval=FALSE, warning=FALSE}
# plot power_output
multiplotPower(power_output)
```

**Note**: multiplotPower automatically saves the plot to the current working directory and you can view it by opening the accordning png-file.

![](/Users/leah/Dropbox/Power/notebooks/multiplot_powerSimulation.png)



&nbsp;

A separate graph for each effect in the model output is plotted. In the current example, the data consisted of 48 participants, thus each power value at 48 corresponds to the actual sample size of the data used to inform the simulation. 

Let's first have a look at morphological complexity (sn.c) as this is the effect we examined with simr as well. The databased estimate in mixedpower and simr provide very similar results for all examined sample sizes. However, the safeguard estimate results in more conservative results than the confidence interval provided by simr (at least with the confidence level used for the present example). Also, it is worth mentioning that runtime for the mixedpower simulation was 14 minutes compared to over 60 hours for simr. 

The remaining effect of word length (wf.c) and launch site (ls.c) as well as their interaction (wf.c:ls.c) had a power of 100% for both the databased and safeguard estimate and all examined sample sizes. The interaction of word length and number of suffixes (wl.c:sn.c) had a power ranging from 94 - 100% (safeguard:80 - 99 %).

Moreover, the interactions ls.c:sn.c and wl.c:ls.c:sn.c seem to have very similar results for the databased and safeguard estimate, both not exceeding 25%. Because sagfeguard power only is available for significant effects in the model used for simulation (FLPmodel), safeguard was not effectively used for here. For more a more detailed explanation for this see the [general introduction](https://lkumle.github.io/power_notebooks/mixedpower_introduction.html) for mixedpower. 

&nbsp;

####**Deciding on a sample size**

Using the output of a power analysis to decide on the necessary sample size requires making multiple decisions. Again, we first need to decide on a goal power and as in our SIMR power simulation we will use 80% as the desired power.

Second, especially when working with mixedpower, we need to decide on which estimate (databased or safeguard) our decision should be based on and which effects are taken into consideration. As the current simulation was based on published data that are likely to be subject to publication bias, using corrected effect size estimates seems reasonable.
Since mixedpower provides power estimates for all effects specified in the model, we need to agree on a strategy on how to combine this information. In doing so, different scenarios come to mind depending on how many effects are of interest. On general, the effect with lowest power should be picked to decide on a sample size for the following study. This makes sure that all effects are adequately powered.

Imagine we are interested in the effects of *world length* (wl.c) and *morphological complexity* (sn.c): As morphological complexity shows lower power values in our simulation, we will use it to decide on a sample size. The databased estimate suggests a sample size of around 40 participants. However, using the safeguard estimate this would not result in adequate power and we would further increase our sample size. 



***
***



###**References**

Bates, D., Maechler, M., Bolker, B., & Walker, S. (2014). Fitting Linear Mixed-Effects Models using lme4. Journal of Staistical Software, 67(1). https://doi.org/10.18637/jss.v067.i01

Brysbaert, M., & Stevens, M. (2018). Power Analysis and Effect Size in Mixed Effects Models: A Tutorial. Journal of Cognition, 1(1), 1???20. https://doi.org/10.5334/joc.10

Green, P., & Macleod, C. J. (2016). SIMR: An R package for power analysis of generalized linear mixed models by simulation. Methods in Ecology and Evolution, 7(4), 493-498. [https://doi.org/10.1111/2041-210X.12504](https://doi.org/10.1111/2041-210X.12504)

Kumle, L., Vo, M. L-H., & Draschkow, D. (2018). Mixedpower: a library for
estimating simulation-based power for mixed models in R. https://doi.org/10.5281/zenodo.1341047

Kumle, L., Vo, M. L-H., & Draschkow, D. (in preparation). Estimating power in linear and generalized linear mixed models: an open introduction and tutorial in R.

Perugini, M., Gallucci, M., & Costantini, G. (2014). Safeguard Power as a Protection Against Imprecise
Power Estimates. Perspectives on Psychological Science, 9(3), 319-332. https://doi.org/10.1177/1745691614528519

Thomas, L., & Juanes, F. (1996). The importance of statistical power analysis: An example from Animal Behaviour. Animal Behaviour, 52(4), 856-859. https://doi.org/10.1006/anbe.1996.0232

Yan, M., Zhou, W., Shu, H., Yusupu, R., Miao, D., Kruegel, A., & Kliegl, R. (2014). Eye movements guided by morphological structure: Evidence from the Uighur language. Cognition, 132(2), 181???215. https://doi.org/10.1016/j.cognition.2014.03.008
