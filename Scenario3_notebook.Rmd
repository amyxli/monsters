---
title: "Scenario 3: Using fitted model from pilot data"
output:
  html_document: default
  word_document: default
---
Kumle, L., Vo, M. L-H., & Draschkow, D.

latest update: March 2019

***
***
Sufficient power and precision in confirmatory analyses is important for reliability, replicability, and interpretation of empirical findings. Calculating power, however, is not necessarily a trivial task and in certain cases this might pose a feasibility barrier to scientists. One of these cases is power analysis for (generalized) liner mixed-effect models (LMMs and GLMMs). They are a powerful tool for modelling fixed and random effects simultaneously, but do not offer a feasible analytic solution to estimate the probability that a test correctly rejects the null hypothesis.
This requires a simulation based solution, which always start with a fitted model to inform the simulation.

In this tutorial, we provide a step-by-step workflow on how to use pilot data to simulate power for a follow-up study. For more background information see Kumle, Vo & Draschkow (in preparation).

***
***


### **Import data**

In this tutorial we will use the *lexdec data* from languageR (Baayen, 2013) and treat it as pilot data. For simplicity we will subset the data set and only keep the variables needed for the following analysis.

```{r}
# get lexdec data set
library(languageR)

#subset data set
tutorial_variables <- c("Subject", "RT", "NativeLanguage", "Word", "Frequency")
LEXDEC <- lexdec[tutorial_variables]
```


The lexdec data contains lexical decision latencies (i.e. how fast a stimuli can be classified as a word or non-word) elicited from 21 subjects for 79 English concrete nouns. Let's have a closer look:

```{r warning=FALSE}
# look at the data
head(LEXDEC)
```

As we can see, RT corresponds to the time it took for a participant to classify a word. NativeLanguage differentiates subjects who have English as their native language or not. Word and Frequency indicates the word that was responded to and its frequency in the English language.


Before we can fit a linear mixed model, we need to preprocess the data set. We will inverse transform reaction times (RT) to a speed measure to adhere to distribution assumptions. Moreover, we will center the continuous covariate Frequency for the ease of fitting and interpretation.
```{r}
library(MASS)
## transform RT
LEXDEC$RT = exp(LEXDEC$RT)
LEXDEC <- transform(LEXDEC, logRT=log(RT), speed=1000/RT )

# using centered frequency as covariate
LEXDEC$Frequency.c <- scale(LEXDEC$Frequency, center=TRUE, scale=FALSE)
LEXDEC$NativeLanguage.c <- ifelse(LEXDEC$NativeLanguage == "English", -1/2, 1/2)
```

&nbsp;

#### **Model fitting**
Using the *lme4* package (Bates, Maechler, Bolker & Walker, 2015), we will perform the power analysis on a model predicting the speed of the lexical decision as a function of word frequency and if the word was in a native or foreign language. By-subject random slopes for Word Frequency and by-item random slopes for the effect of Native Language are included in the random effects structure of the model. Note that the process of model fitting and selecting an optimal model is beyond the scope of this Notebook and is left out in this example for simplicity.

```{r message=FALSE, warning=FALSE}
library(lme4)

## this is the final model
SPEEDmodel <- lmer(speed ~ NativeLanguage.c * Frequency.c + (1  + Frequency.c | Subject) + 
                   (1 + NativeLanguage.c | Word), data=LEXDEC)

## lets have a look at this model
summary(SPEEDmodel, corr = FALSE)
```

The summary of the fixed effects part of the model indicates a significant main effect of Native Language, one of Word Frequency and a significant interaction.
That is, words in the native language (in this case English) were processed faster compared to foreign words (figure below). Additionally, high frequency words were responded to faster than low frequency words, but the significant interaction demonstrates that this speed increase was more prominent for foreign words.

![](/Users/leah/Dropbox/Power/notebooks/Scenario 3/Lexdec_SPEEDmodel_plot.png)

***
***

### **Power Analysis with mixedpower**

First, we will conduct a power analysis with mixedpower. A more detailed tutorial and introduction can be found [here](https://lkumle.github.io/power_notebooks/mixedpower_introduction.html) or in [Notebook 1](https://lkumle.github.io/power_notebooks/Scenario1_notebook.html).

Once the library is loaded, we can use the mixedpower() function to perform the power analysis. In the following section, we will shortly elaborate on each argument required by mixedpower. Again, for a more detailed description and an explanation about the inner working of the function see the [general introduction](https://lkumle.github.io/power_notebooks/mixedpower_introduction.html) to mixedpower.


```{r eval=FALSE, message=FALSE, warning=FALSE}
library(mixedpower)

#core function to perform power analysis
mixedpower(model_emp, data_emp, subvar,fixed_effects,
           sample_sizes, n_sim, critical_value, confidence_level,
           databased = T, safeguard = T, rnorm = F)

```

&nbsp;

##### **Empirical data and model**


We can use our fitted model (model_emp = SPEEDmodel) and our data frame as the data set (data_emp = LEXDEC).

The function requires further specifics about the data at hand in order to include all necessary information into the simulation.  We need to provide the names of the fixed effects and covariates we have included in our model ("NativeLanguage.c", "Freqency.c") as well as the name of the column containing the participant identifier ("Subject").

```{r}
# specfiy needed information about data set
model_emp <- SPEEDmodel
data_Emp <- LEXDEC
subvar <- "Subject"
fixed_effects <- c("NativeLanguage.c", "Freqency.c")
```

&nbsp;

##### **Simulation of multiple data sets**

We further need to specify how many simulations we want to run (n_sim) and which possible future sample sizes we are interested in (sample_sizes).

```{r}
# simulation parameters
n_sim <- 1000
sample_sizes <- c(15, 21, 30, 45)
```

&nbsp;


##### **Test of statistical significance**
Deciding if an effect exceeds a significance threshold is a critical aspect of every simulation-based power analysis and heavily influences its outcome as power is computed as the relation of significant to all simulations. However, mixedpower relies on lme4, which does not provide p-values.

Mixedpower therefore works with the available t values for linear mixed models or z values for generalized linear mixed models. Concluding, we need to set a critical_value in form of a t or z values depending on the model on hand and all coefficients exceeding this value would be counted as significant. In the present example, we decided to set critical_value = 2.

```{r}
# set critical_value
critical_value <- 2
```

&nbsp;

##### **Protection against bias in data**

The accuracy of a simulation-based calculation of power and its interpretability is dependent on how well the model is capturing the data (Thomas & Juanes, 1996) and on how well the data is capturing the underlying effect of interest. Especially data consisting of only few observations or participants (e.g. from pilot or exploratory studies) carry the risk of uncertainty in respect to effects in the data.

Mixedpower offers an adaptation of *safeguard power* proposed by Perugini, Gallucci, & Costantini (2014). In this approach, a confidence interval is computed around the beta coefficients in the model used for simulation. Using the lower bound of the interval leads to a more conservative simulation. In the present example we decided on a confidence interval of 80%.

```{r}
# set width of confidence interval
confidence_level <- 0.80
```

*Note:* Safeguard power is available for significant effects only. See the [general introduction](https://lkumle.github.io/power_notebooks/mixedpower_introduction.html) to mixedpower for more details.
&nbsp;

##### **Power simulation**

We now can run the power simulation for the data at hand. For this, we will use the function mixedpower() which handles and combines simulations for all specified sample sizes and provides us with a power estimate derived from the actual effect sizes of the data (databased), as well as the conservative estimate of safeguard power (safeguard). The relevant parameters specified in the steps above will be used.

```{r eval=FALSE, warning=FALSE}
# run power analysis
power_output <- mixedpower(SPEEDmodel, LEXDEC, subvar, fixed_effects,
                           sample_sizes, n_sim, critical_value,confidence_level,
                           databased = T, safeguard = T)
```

Runtime for the simulation process heavily depends on the chosen number of simulations and the capacity of the used machine. As mixedpower runs its simulation in parallel on all but one available cores, runtime decreases the more cores are available.

&nbsp;

##### **Interpreting and visualizing the power analysis **

The output provided by mixedpower() contains power values for every effect and all specified sample sizes. The power values are provided both from the original effect sizes (databased) or the corrected conservative estimates (safeguard).

```{r include=FALSE}
# plot power_output
load("/Users/leah/Dropbox/Power/notebooks/Scenario 3/lexdec_power_1000.RData")
```

```{r}
power_output
```

***

For visualization and an easier interpretation of the power simulation results, mixedpower provides the function multiplotPower(), which plots power as a function of sample size.



```{r eval=FALSE, warning=FALSE}
# plot power_output
multiplotPower(power_output)
```



![](/Users/leah/Dropbox/Power/notebooks/Scenario 3/plots_manuscript.png)


In the current example, the data consisted of 21 participants, thus each power value at 21 corresponds to the power for the data's actual sample size . That is, the effect of Native Language had a power of 70%, the one of Frequency 100% and the interaction was at 56%. As to be expected, power is lower for smaller sample sizes and higher for larger ones. For this data, each participant would have added about 1% per participant for all effects, except for the one at ceiling. The conservative safeguard estimated lower power values for both non-ceiling effects. Its slope was similar to the databased estimates for the effect of Native Language, but not as steep for the interaction.

&nbsp;

To use this output to decide on a sample size for our future study, we first need to agree on a goal power.  A well-known threshold value for the probability of finding an effect in cognitive neuroscience and psychology is 80% and represents a compromise between the need for adequate power and the effort/cost needed to further increase power (Brysbaert & Stevens, 2018). Using this threshold and the databased estimate, we would aim to test around 45 subjects. Taking the safeguard estimate into account would increase this number even more.



***
***

###**Smallest effect size of interest with SIMR**


Another tool appropriate for simulation-based power analysis with pilot studies is the package SIMR (Green& Macleod, 2016). SIMR allows to manually change the beta coefficients in the model used for simulations. Changing it to the smallest effect size of interest therefore allows to design studies which are worthwhile to run as they have a pre-determined power to detect an effect of interest (Albers & Lakens, 2018). For a more precise treatment of the different functions included in SIMR see [Green & Macleod (2016)](https://doi.org/10.1111/2041-210X.12504) and the other notebooks included in this tutorial.

To run a power simulation based on the smallest effect size of interest (SESOI) in SIMR, we first need to load the according package:
```{r warning=FALSE}
# load SIMR
library(simr)
```

&nbsp;

#####**Set effct size**
The next and most important step is to determine the smallest effect size of interest. This could be based on previous research, literature or practical reasons. As SIMR allows to simulate power for only one effect at a time, we will focus on the first effect in our model  (NativeLaguage.c). In the present example, we will keep it consistent with the mixedpower power analysis and use the safeguard effect size as our smallest effect size of interest. In the case of Native Language, the effect size computed by safeguard power is -0.11764.

Using the fixef()- function, we can set the value of the corresponding beta coefficient to -0.11764.

```{r}
# create copy of model to not overwrite the original one (SESOI = smallest effect size of interest)
SPEEDmodel_SESOI <- SPEEDmodel

# set beta coefficient to smallest effect size of interest
fixef(SPEEDmodel_SESOI)["NativeLanguage.c"] <- -0.11764

# lets have a look at the modified model
summary(SPEEDmodel_SESOI, corr = F)
```


#####**Run power analysis**

All we have to do now is to run the SIMR power analysis. SIMR provides a simple function called powerSim() that runs the power simulation.

```{r eval = F}
# run power analysis
power <- powerSim(SPEEDmodel_SESOI, test= fixed("NativeLanguage.c"))
```

```{r include=FALSE}

load("~/Dropbox/Power/notebooks/Scenario3_simr.Rdata")
```

```{r}
# let's have a look!
print(power)
```
To explore power over a range of different sample sizes, the powerCurve() function can be used. This is especially useful if the power analysis is used to decide on an adequate sample size. To do so, we first need to "extend" our artificial data set to largest sample size we are interested in. SIMR provides an extend()- function that simply duplicates the existing data set to the intended sample size.

As power concerning Native Language for 21 subjects is 20,5%, we will simulate power for 30, 40, 50, and 60 participants to explore power for larger sample sizes. Accordingly, we will extend our data set to 60 participants.

```{r eval = F}
# 1. extend data set
SPEEDmodel_SESOI_extended <- extend(SPEEDmodel_SESOI, along="Subject", n=60)
```

Now we can use the extended model to run a power analysis over different sample sizes.
```{r eval = F}
# 2. run power curve
powerC <- powerCurve(SPEEDmodel_SESOI_extended, test= fixed("NativeLanguage.c"))
```


Let's have a look at the results:
```{r include=FALSE}
load("/Users/leah/Dropbox/Power/notebooks/simr_powerCurve_scenario3_SESOI.Rdata")
```

```{r}
print(powerC)
```

It becomes apparent that increasing the sample size to 60 is still not enough to reach adequate power if our smallest effect of interest is -0.11764. We would have to run another power simulation and increase the sample size even more to decide on a sample size that results in power of more than 80%.

**Note:** Once we created an artificial model, the power analysis could also be conducted with other available tools like *mixedpower* (Kumle, Vo, & Draschkow, 2018).


***
***

####**References**

Albers, C., & Lakens, D. (2018). When power analyses based on pilot data are biased: Inaccurate effect size estimators and follow-up bias. Journal of Experimental Social Psychology. https://doi.org/10.1016/j.jesp.2017.09.004

Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015). Fitting Linear Mixed-Effects Models Using lme4. Journal of Statistical Software, 67(1), 1-48.
doi:10.18637/jss.v067.i01.

R. H. Baayen (2013). languageR: Data sets and functions with
"Analyzing Linguistic Data: A practical introduction to statistics". R package version 1.4.1. https://CRAN.R-project.org/package=languageR

Brysbaert, M., & Stevens, M. (2018). Power Analysis and Effect Size in Mixed Effects Models: A Tutorial. Journal of Cognition, 1(1), 1???20. https://doi.org/10.5334/joc.10

Green, P., & Macleod, C. J. (2016). SIMR: An R package for power analysis of generalized linear mixed models by simulation. Methods in Ecology and Evolution, 7(4), 493???498. [https://doi.org/10.1111/2041-210X.12504](https://doi.org/10.1111/2041-210X.12504)

Kumle, L., Vo, M. L-H., & Draschkow, D. (2018). Mixedpower: a library for
estimating simulation-based power for mixed models in R. https://doi.org/10.5281/zenodo.1341047

Kumle, L., Vo, M. L-H., & Draschkow, D. (in preparation). Estimating power in linear and generalized linear mixed models: an open introduction and tutorial in R.

Perugini, M., Gallucci, M., & Costantini, G. (2014). Safeguard Power as a Protection Against Imprecise
Power Estimates. Perspectives on Psychological Science, 9(3), 319-332. https://doi.org/10.1177/1745691614528519

Thomas, L., & Juanes, F. (1996). The importance of statistical power analysis: An example from Animal Behaviour. Animal Behaviour, 52(4), 856-859. https://doi.org/10.1006/anbe.1996.0232
