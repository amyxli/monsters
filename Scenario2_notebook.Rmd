---
title: "Scenario 2: Having strong and detailed a priori assumptions "
output:
  html_document: default
  word_document: default
---

Kumle, L., Vo, M. L-H., & Draschkow, D.

latest update: August 2019

***
***
Sufficient power and precision in confirmatory analyses is important for the reliability, replicability, and interpretation of empirical findings. Calculating power, however, is not necessarily a trivial task and in certain cases this might pose a feasibility barrier to scientists. One of these cases is power analysis for (generalized) liner mixed-effect models (LMMs and GLMMs). They are a powerful tool for modelling fixed and random effects simultaneously, but do not offer a feasible analytic solution to estimate the probability that a test correctly rejects the null hypothesis.

This requires a simulation based solution, which always start with a fitted model to inform the simulation. Generally, some sort of data is required to fit a model with lme4. However, there are certain scenarios where such data is either not available yet or a researcher already has strong experience and beliefs about a specific effect. SIMR can be used to create lme4 objects from scratch without fitting it to actual data (Green & Macleod, 2016).

In this tutorial, we provide a step-by-step workflow on how to set up such a model and use it to simulate power for a following study. For more detailed information see Kumle, Vo & Draschkow (in preparation).

***
***
###**Setting up a model from scratch with SIMR**

&nbsp;

First, we need to install and load the SIMR package (Green & Macleod, 2016). Note that SIMR only needs to be installed once and loading the package is sufficient once it is installed.

```{r eval=FALSE, message=FALSE, warning=FALSE}
# install SIMR
install.packages("simr")
```

```{r message=FALSE, warning=FALSE}
# load SIMR
library(simr)
```

***

#### Setting Parameters

&nbsp;

Setting up a model from scratch implies that we need to specify all included parameters by ourselves and those parameters could be informed and justified through previous work, literature, experience, and knowledge. Being able to justify those parameters is key in order for the following power analysis to be useful as the simulation for a following study is only accurate when the effect size estimates are accurate (Albers & Lakens, 2018) Therefor, considerable thought should be put into this. Unfortunately, giving general advice on this is hard as this process is highly dependent on the research question on hand.

**Example Study**
For the present tutorial, we will pretend to plan a study investigating the effect of participant's native language (English or non-English) in a lexical decision task (i.e. participants are asked to decided if some displayed letters form a word or not). Besides native language we are also interested in the effect of how common a displayed word is in the English language (i.e. word frequency) as well as the interaction between both and we will measure reaction times/speed as a dependent variable.

To simulate power for our study, we therefor need to set up a model displaying the effect of native language and word frequency on the speed of lexical decisions. The intended lme4 formula for this model can be seen here:

```{r}
# formula for artificial model
formula <- speed ~ NativeLanguage * Frequency + (1 | Subject) + (1 | Word)
```

&nbsp;

**Create Artifical Data**


To set up the simulation, we first need to create an artificial data set containing all important covariates. Let's assume our following study will consists of participants reading 100 words in English while performing a lexical decision task and as seen in our formula above we want to include the variables "subject" and "word" as random effects. Therefore, we will build an artificial data set containing our random effects first.

We will use expand.grid() to do so:  
```{r}
# 1. create subject variable.
# We will start with 20 subjects - changes in the number of subjects can be done later
subject <- (1:20)

# 2. create word variable.
# We decided to include 100 words in our study
word <- (1:100)

# combine them in one data set
artificial_data <- expand.grid(Word = word, Subject = subject)
```

Next, we also need to include our fixed effects *native language* and *word frequency*. We will distinguish between "native" and "foreign" as levels for our variable native language and aim to test a balanced number of participants who have English as their native language and not. We will create a vector containing 0.5 and -0.5 to indicate the different levels of native language as this already centers our variable.  
To include *word frequency* in our example we will generate random frequency ratings. However, in a real world example we would have already selected 100 words including their frequency ratings.

```{r}
# 1. create vector containing values to indicate native language
# as we want 10 participants in every level who each respond to 100 stimuli we need a vector of length 2000 (=2*10*100)
native_language <- c(rep(-0.5, 1000), rep(0.5, 1000))

# include it in our data set
artificial_data["NativeLanguage"] <- native_language

```

```{r}
# 2. generate frequency ratings
# [This step should be replaced with actual ratings!]
frequency_ratings <- runif(100)

# create vector for data set: Multiple by 20 as we have 20 subject in our artificial data set who each respond to all words
frequency <- sort(rep(frequency_ratings, 20))

#reorder artificial data so that every word corresponds to one frequency rating
artificial_data <- artificial_data[order(artificial_data$Word),]
# match frequency with words
artificial_data["Frequency"] <- frequency
```
&nbsp;

**Specify Fixed and Random Parameters**

In a next step, we need to specify parameters for our fixed and random effects. This represents the most important step as these are the parameters used to inform the following power simulation. The parameters needed to create an artificial model include a vector of fixed effects including an intercept and the variance and covariances for random effects.

Let's start with a vector of fixed effects. In our present example the fixed effects are NativeLanguage and Frequency and informed through previous work and literature we have a precise idea on how big this effect is likely going to be in our study.

```{r}
# 1. set fixed effects and intercept
# First value responds to the intercept, the following values should be in the same order as the fixed effects specified in the formula (speed ~ NativeLanguage * Frequency + (1 | Subject) + (1 | Word)
# NOTE: As our formula contains an interaction, we also need to specify a value for this!
fixed_effects <- c(1.7, -0.25, 0.02, 0.03)
```

Next, we need to specify the variance and covariance of the random effects. Since we have more than one random effect, we need to provide them in a list. Again, those values should be informed by previous work and literature.

```{r}
# 2. set random intercept variance
random_variance <- list(0.007, 0.05)
```

***

### Create Artifical Model

&nbsp;

We can now use all specified information and combine them into an artificial model using the makeLmer() or makeGlmer() functions provided by SIMR. Explore ?makeLmer or ?makeGlmer to get help on specific arguments.

&nbsp;

**Create Lmer**

As we are interested in the reaction time (or speed) during the lexical decision task and this is a continuous measurement, makeLmer is the right choice. The help page tells us that we also need to specify a residual standard deviation in this case. Again, guidance on this parameter could originate from prior research or other sources.

```{r}
# 1. set residual standard deviation
sigma <- 0.26
```

To generate our artificial Lmer, we simply hand all specified information to the makeLmer()-function:
```{r}
# 2. create lmer
artificial_lmer <- makeLmer(formula = Speed ~ NativeLanguage * Frequency + (1 | Subject) + (1 | Word),
                           fixef = fixed_effects, VarCorr = random_variance, sigma = sigma,
                           data = artificial_data)

# lets have a look!
summary(artificial_lmer)
```

&nbsp;

**Create Glmer**

Since SIMR also provides the makeGlmer() function, let's have a quick look at it! The only difference compared to the makeLmer() function is that we need to specify a "family"" instead of a residual standard deviation (sigma).
Pretending we wanted to model a variable indicating if participants correctly classified the words during the lexical decision task, we would use a binary response measurement "Correct" and therefor would need a GLMM to model it.
A hypothetical formula could look like this:

```{r}
# formula for GLMM
formula_glmer <- Correct ~ NativeLanguage * Frequency + (1 | Subject) + (1 | Word)
```

So let's create a corresponding glmer. Again, we simply hand all necessary information to the appropriate SIMR function:

```{r}
# create glmer
artificial_glmer <- makeGlmer(formula = Correct ~ NativeLanguage * Frequency + (1 | Subject)
                              + (1 | Word),
                              family = "poisson", fixef = fixed_effects, VarCorr = random_variance,
                              data = artificial_data)

# lets have a look!
summary(artificial_glmer)
```

***
***

### **Power Analysis with SIMR**

&nbsp;

Now that we have a model on hand, we can start with the actual power analysis in SIMR. In this tutorial we will conduct a simple power analysis for our artificial LMM. For a more precise treatment of the different functions included in SIMR see [Green & Macleod (2016)](https://doi.org/10.1111/2041-210X.12504) and the other notebooks included in this tutorial.

SIMR provides an easy-to-use function that runs the whole power simulation called powerSim(). Note that SIMR can only simulate power for one fixed effect at a time. If a model has more than one fixed effect, we need to specify which effect we want to test. We will start with "NativeLanguage" and will simulate power for "Frequency" and the interaction later on.  

```{r eval=FALSE, warning=FALSE}
# run power analysis
power <- powerSim(artificial_lmer, test= fixed("NativeLanguage"))

```

```{r include=FALSE}
# let's have a look!
load("~/Dropbox/Power/notebooks/simr_power_scenario2_lmer.Rdata")
```

```{r}
# let's have a look!
print(power)
```

To explore power over a range of different sample sizes, the powerCurve() function can be used. This is especially useful if the power analysis is used to decide on an adequate sample size. To do so, we first need to "extend" our artificial data set to largest sample size we are interested in. SIMR provides an extend()- function that simply duplicates the existing data set to the intended sample size. Assuming we also want to explore power for sample sizes of 30, 40 and 50, we will extend the artificial data used to fit our artificial model to 50.

```{r eval = F}
# 1. extend data set
artificial_model_extended <- extend(artificial_lmer, along="Subject", n=50)
```

Now we hand our "extended" model to the powerCurve()- function. "Along" and "breaks" refer to the variable used to subset the extended model and the levels we want it to subset respectively.

```{r eval = F}
# 2. run power curve
powerC <- powerCurve(artificial_model_extended, test= fixed("NativeLanguage"), along = "Subject", breaks =c(30,40,50))

```

```{r include=FALSE}
# let's have a look!
load("~/Dropbox/Power/notebooks/simr_powerCurve_scenario2_lmer.Rdata")
```

```{r}
# let's have a look!
print(powerC)
```

**Note:** Once we created an artificial model, the power analysis could also be conducted with other available tools like *mixedpower* (Kumle, Vo, & Draschkow, 2018). For a more precise treatment on how to run and interpret a power analysis in mixedpower or SIMR see [Notebook linked to Scenario 1](https://lkumle.github.io/power_notebooks/Scenario1_notebook.html).

***
***

### **Conclusion**

&nbsp;

Building a model from scratch can be a very useful alternative for setting up a simulation-based power analysis, especially when a lot of prior knowledge concerning the effects of interest exist. Moreover, it allows to inspect small changes in parameters as it is possible to create different plausible models and simulate power for all of them. This way, implications for sample size recommendations can be investigated.
However, as also seen in this tutorial justifying the parameters used to build the model can be difficult. The more complex a model, the more difficult it can become to correctly estimate the structure of the data and to conduct a useful power analysis.


***
***

### **References**

Albers, C., & Lakens, D. (2018). When power analyses based on pilot data are biased: Inaccurate effect size estimators and follow-up bias. Journal of Experimental Social Psychology. https://doi.org/10.1016/j.jesp.2017.09.004

Green, P., & Macleod, C. J. (2016). SIMR: An R package for power analysis of generalized linear mixed models by simulation. Methods in Ecology and Evolution, 7(4), 493-498. [https://doi.org/10.1111/2041-210X.12504](https://doi.org/10.1111/2041-210X.12504)

Kumle, L., Vo, M. L-H., & Draschkow, D. (2018). Mixedpower: a library for
estimating simulation-based power for mixed models in R. https://doi.org/10.5281/zenodo.1341047

Kumle, L., Vo, M. L-H., & Draschkow, D. (in preparation). Estimating power in linear and generalized linear mixed models: an open introduction and tutorial in R.
